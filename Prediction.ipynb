{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import Series,DataFrame\n",
    "\n",
    "data = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\",header=None)\n",
    "data.columns = ['age','workclass','fnlwgt','education','education-num','marital-status','occupation','relationship','race','sex','capital-gain','capital-loss','hours-per-week','native-country','salary-class']\n",
    "occ = data['occupation'].value_counts()\n",
    "wor = data['workclass'].value_counts()\n",
    "capacity = wor.sum() #32561"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C= 0.1 Accuracy of the predictor on the train data is: 0.760626535627\n",
      "C= 0.1 Accuracy of the predictor on the test data is: 0.757800982801\n"
     ]
    }
   ],
   "source": [
    "# prediction\n",
    "# data extractionï¼š5 continuous features\n",
    "# age, education-num, capital-gain, capital-loss, hours-per-week\n",
    "age = data['age']\n",
    "eduNum = data['education-num']\n",
    "capGain = data['capital-gain']\n",
    "capLoss = data['capital-loss']\n",
    "hpw = data['hours-per-week']\n",
    "salary = data['salary-class']\n",
    "assert ' ?' not in age.value_counts().index  # no missing data\n",
    "assert ' ?' not in eduNum.value_counts().index\n",
    "assert ' ?' not in hpw.value_counts().index\n",
    "assert ' ?' not in capGain.value_counts().index\n",
    "assert ' ?' not in capLoss.value_counts().index\n",
    "assert ' ?' not in salary.value_counts().index\n",
    "age = age.tolist()\n",
    "eduNum = eduNum.tolist()\n",
    "capGain = capGain.tolist()\n",
    "capLoss = capLoss.tolist()\n",
    "hpw = hpw.tolist()\n",
    "salary = salary.tolist()\n",
    "X = []\n",
    "Y = []\n",
    "for i in range(capacity):\n",
    "    X.append([age[i],eduNum[i],hpw[i]])\n",
    "    Y.append(salary[i] == ' >50K')\n",
    "    \n",
    "# SVM Classification\n",
    "import scipy.optimize\n",
    "import random\n",
    "from sklearn import svm\n",
    "\n",
    "scale_half = int(capacity/2)\n",
    "X_train = X[:scale_half]\n",
    "Y_train = Y[:scale_half]\n",
    "X_test = X[scale_half:]\n",
    "Y_test = Y[scale_half:]\n",
    "\n",
    "c = 0.1\n",
    "clf = svm.SVC(C=c, kernel='linear')\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "train_predictions = clf.predict(X_train)\n",
    "test_predictions = clf.predict(X_test)\n",
    "\n",
    "train_correct = 0\n",
    "for i in range(scale_half):\n",
    "    if train_predictions[i] == Y_train[i]:\n",
    "        train_correct = train_correct + 1\n",
    "train_acc = train_correct/float(scale_half)\n",
    "test_correct = 0\n",
    "for i in range(scale_half):\n",
    "    if test_predictions[i] == Y_test[i]:\n",
    "        test_correct = test_correct + 1\n",
    "test_acc = test_correct/float(scale_half)\n",
    "print \"C=\",c,\"Accuracy of the predictor on the train data is:\",train_acc\n",
    "print \"C=\",c,\"Accuracy of the predictor on the test data is:\",test_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final log likelihood = -8613.946116166113\n",
      "Accuracy of predictor in train data =  0.797235872236\n",
      "Accuracy of predictor in test data =  0.797604422604\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "from math import exp\n",
    "from math import log\n",
    "import scipy.optimize\n",
    "import random\n",
    "import numpy\n",
    "\n",
    "def inner(x,y):\n",
    "    return sum([x[i]*y[i] for i in range(len(x))])\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1 + exp(-x))\n",
    "\n",
    "# NEGATIVE Log-likelihood\n",
    "def f(theta, X, y, lam):\n",
    "    loglikelihood = 0\n",
    "    for i in range(len(X)):\n",
    "        logit = inner(X[i], theta)\n",
    "        loglikelihood -= log(1 + exp(-logit))\n",
    "        if not(y[i]==True):\n",
    "            loglikelihood -= logit\n",
    "    for k in range(len(theta)):\n",
    "        loglikelihood -= lam * theta[k]*theta[k]\n",
    "    #print (\"ll =\", loglikelihood)\n",
    "    return -loglikelihood\n",
    "\n",
    "# NEGATIVE Derivative of log-likelihood\n",
    "def fprime(theta, X, y, lam):\n",
    "    dl = [0.0]*len(theta)\n",
    "    for k in range(len(theta)): \n",
    "        for i in range(len(X)):\n",
    "            logit = inner(X[i], theta)\n",
    "            dl[k] += X[i][k]*(exp(-logit))/(1 + exp(-logit))\n",
    "            if not(y[i]==True):\n",
    "                dl[k] -= X[i][k]\n",
    "        dl[k] -= 2*lam*theta[k]\n",
    "  # Negate the return value since we're doing gradient *ascent*\n",
    "    return numpy.array([-x for x in dl])  \n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "for i in range(capacity):\n",
    "    X.append([age[i],eduNum[i],capGain[i],capLoss[i],hpw[i]])\n",
    "    Y.append(salary[i] == ' >50K')\n",
    "\n",
    "scale_half = int(capacity/2)\n",
    "X_train = X[:scale_half]\n",
    "Y_train = Y[:scale_half]\n",
    "X_test = X[scale_half:]\n",
    "Y_test = Y[scale_half:]\n",
    "theta,l,info = scipy.optimize.fmin_l_bfgs_b(f, [0]*len(X[0]), fprime, args = (X_train, Y_train, 1.0))\n",
    "print \"Final log likelihood =\", -l\n",
    "\n",
    "YPre_train = []\n",
    "for i in range(scale_half):\n",
    "    x_theta = 0\n",
    "    for j in range(len(theta)):\n",
    "        x_theta += X_train[i][j]*theta[j]\n",
    "    if x_theta > 0:\n",
    "        YPre_train.append(1)\n",
    "    else:\n",
    "        YPre_train.append(0)\n",
    "count = 0\n",
    "for i in range(scale_half):\n",
    "    if Y_train[i] == YPre_train[i]:\n",
    "        count = count + 1\n",
    "acc = count/float(scale_half)\n",
    "print \"Accuracy of predictor in train data = \", acc\n",
    "\n",
    "YPre_test = []\n",
    "for i in range(scale_half):\n",
    "    x_theta = 0\n",
    "    for j in range(len(theta)):\n",
    "        x_theta += X_test[i][j]*theta[j]\n",
    "    if x_theta > 0:\n",
    "        YPre_test.append(1)\n",
    "    else:\n",
    "        YPre_test.append(0)\n",
    "count = 0\n",
    "for i in range(scale_half):\n",
    "    if Y_test[i] == YPre_test[i]:\n",
    "        count = count + 1\n",
    "acc = count/float(scale_half)\n",
    "print \"Accuracy of predictor in test data = \", acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda =  0 Accuracy of predictor in train data =  0.797235872236\n",
      "lambda =  0 Accuracy of predictor in test data =  0.797604422604\n",
      "lambda =  0.01 Accuracy of predictor in train data =  0.797235872236\n",
      "lambda =  0.01 Accuracy of predictor in test data =  0.797604422604\n",
      "lambda =  0.1 Accuracy of predictor in train data =  0.797235872236\n",
      "lambda =  0.1 Accuracy of predictor in test data =  0.797604422604\n",
      "lambda =  1 Accuracy of predictor in train data =  0.797235872236\n",
      "lambda =  1 Accuracy of predictor in test data =  0.797604422604\n",
      "lambda =  10 Accuracy of predictor in train data =  0.797235872236\n",
      "lambda =  10 Accuracy of predictor in test data =  0.797604422604\n",
      "lambda =  100 Accuracy of predictor in train data =  0.797235872236\n",
      "lambda =  100 Accuracy of predictor in test data =  0.797665847666\n",
      "lambda =  1000 Accuracy of predictor in train data =  0.797174447174\n",
      "lambda =  1000 Accuracy of predictor in test data =  0.79785012285\n",
      "lambda =  10000 Accuracy of predictor in train data =  0.79742014742\n",
      "lambda =  10000 Accuracy of predictor in test data =  0.798218673219\n",
      "lambda =  100000 Accuracy of predictor in train data =  0.797665847666\n",
      "lambda =  100000 Accuracy of predictor in test data =  0.798464373464\n"
     ]
    }
   ],
   "source": [
    "# biased P_error with lambda\n",
    "for lam in [0,0.01,0.1,1,10,100,1000,10000,100000]:\n",
    "    theta,l,info = scipy.optimize.fmin_l_bfgs_b(f, [0]*len(X[0]), fprime, args = (X_train, Y_train, lam))\n",
    "    #print \"Final log likelihood =\", -l\n",
    "\n",
    "    YPre_train = []\n",
    "    for i in range(scale_half):\n",
    "        x_theta = 0\n",
    "        for j in range(len(theta)):\n",
    "            x_theta += X_train[i][j]*theta[j]\n",
    "        if x_theta > 0:\n",
    "            YPre_train.append(1)\n",
    "        else:\n",
    "            YPre_train.append(0)\n",
    "    count = 0\n",
    "    for i in range(scale_half):\n",
    "        if Y_train[i] == YPre_train[i]:\n",
    "            count = count + 1\n",
    "    acc = count/float(scale_half)\n",
    "    print \"lambda = \", lam, \"Accuracy of predictor in train data = \", acc\n",
    "\n",
    "    YPre_test = []\n",
    "    for i in range(scale_half):\n",
    "        x_theta = 0\n",
    "        for j in range(len(theta)):\n",
    "            x_theta += X_test[i][j]*theta[j]\n",
    "        if x_theta > 0:\n",
    "            YPre_test.append(1)\n",
    "        else:\n",
    "            YPre_test.append(0)\n",
    "    count = 0\n",
    "    for i in range(scale_half):\n",
    "        if Y_test[i] == YPre_test[i]:\n",
    "            count = count + 1\n",
    "    acc = count/float(scale_half)\n",
    "    print \"lambda = \", lam, \"Accuracy of predictor in test data = \", acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda = 1.0:\taccuracy of training set = 0.7972358722358722\n",
      "lambda = 1.0:\taccuracy of test set = 0.797616854001597\n",
      "TP = 1051 TN = 11935 FP = 402 FN = 2893\n",
      "BER of classifier on test set is 0.149532818706\n"
     ]
    }
   ],
   "source": [
    "def train(lam):\n",
    "    theta,_,_ = scipy.optimize.fmin_l_bfgs_b(f, [0]*len(X[0]), fprime, pgtol = 10, args = (X_train, Y_train, lam))           \n",
    "    return theta\n",
    "\n",
    "def performance(theta, X, y):\n",
    "    scores = [inner(theta,x) for x in X]\n",
    "    predictions = [s > 0 for s in scores]\n",
    "    correct = [(a==b) for (a,b) in zip(predictions,y)]\n",
    "    acc = sum(correct) * 1.0 / len(correct)\n",
    "    return acc\n",
    "\n",
    "#BER Calculation\n",
    "def ber(theta, X, y):\n",
    "    scores = [inner(theta, x) for x in X]\n",
    "    predictions = [s > 0 for s in scores]\n",
    "    TP = [(a==1 and b==1) for (a,b) in zip(predictions, y)]\n",
    "    TN = [(a==0 and b==0) for (a,b) in zip(predictions, y)]\n",
    "    FP = [(a==1 and b==0) for (a,b) in zip(predictions, y)]\n",
    "    FN = [(a==0 and b==1) for (a,b) in zip(predictions, y)]\n",
    "    tp = sum(TP)\n",
    "    tn = sum(TN)\n",
    "    fp = sum(FP)\n",
    "    fn = sum(FN)\n",
    "    print(\"TP = \"+str(tp)+\" TN = \"+str(tn)+\" FP = \"+str(fp)+\" FN = \"+str(fn))\n",
    "    BER = 1-0.5*(float(fn)/(tp+fn)+float(tn)/(tn+fp))\n",
    "    return BER\n",
    "\n",
    "lam = 1.0\n",
    "\n",
    "Theta_1 = train(lam)\n",
    "acc1 = performance(Theta_1, X_train, Y_train)\n",
    "acc2 = performance(Theta_1, X_test, Y_test)\n",
    "\n",
    "print (\"lambda = \" + str(lam) + \":\\taccuracy of training set = \" + str(acc1))\n",
    "print (\"lambda = \" + str(lam) + \":\\taccuracy of test set = \" + str(acc2))\n",
    "\n",
    "BER_1 = ber(Theta_1, X_test, Y_test)\n",
    "print(\"BER of classifier on test set is \"+str(BER_1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
